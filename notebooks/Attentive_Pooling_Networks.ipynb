{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4abeebc5",
   "metadata": {},
   "source": [
    "# Attentive Pooling Networks\n",
    "## Combined: BiLSTMs and CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124708d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import string\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.metrics import average_precision_score\n",
    "import datasets\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "\n",
    "GLOVE_FILE = '/hdd/data/NLP_data/word_vectors/glove.6B/glove.6B.300d.txt' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9deec78",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086d2d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "TRAIN_EPOCHS = 20\n",
    "BATCH_SIZE = 20\n",
    "TEST_BATCH_SIZE = 128\n",
    "LOSS_MARGIN = 0.5\n",
    "TRAIN_NEG_COUNT = 50  # Amount of random negative answers for every question in training\n",
    "Q_LENGTH = 20\n",
    "A_LENGTH = 100\n",
    "PAD_WORD = '<UNK>'  \n",
    "KERNEL_COUNT = 400\n",
    "KERNEL_SIZE = 3\n",
    "RNN_HIDDEN = 150\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f6a7aa",
   "metadata": {},
   "source": [
    "### Select questions-answer pairs with atleast one correct answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f39e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_questions(wikiqa):\n",
    "    question_status = dict()\n",
    "\n",
    "    for split in wikiqa:\n",
    "        split_dataset = wikiqa[split]\n",
    "        n_samples = len(split_dataset)\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            qid = split_dataset[i]['question_id']\n",
    "            label = split_dataset[i]['label']\n",
    "            if qid not in question_status:\n",
    "                question_status[qid] = label\n",
    "            else:\n",
    "                question_status[qid] = max(question_status[qid], label)\n",
    "\n",
    "    valid_questions = set([qid for qid in question_status if question_status[qid] > 0])\n",
    "    \n",
    "    return valid_questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93645849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_qa (/home/at/.cache/huggingface/datasets/wiki_qa/default/0.1.0/d2d236b5cbdc6fbdab45d168b4d678a002e06ddea3525733a24558150585951c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2e5a4f7a5c4215bd4d53a00eaf6735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63eac2c3128244b5849715dc6e7739cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1ff4a8e85142079efe9fb4f0e458ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e2613178fe4aaa8547a8a093805b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['question_id', 'question', 'document_title', 'answer', 'label'],\n",
       "        num_rows: 2351\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question_id', 'question', 'document_title', 'answer', 'label'],\n",
       "        num_rows: 1130\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['question_id', 'question', 'document_title', 'answer', 'label'],\n",
       "        num_rows: 8672\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikiqa = load_dataset('wiki_qa')\n",
    "valid_questions = get_valid_questions(wikiqa)\n",
    "wikiqa_f = wikiqa.filter(lambda sample: sample['question_id'] in valid_questions)\n",
    "\n",
    "wikiqa_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b5e50f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1040"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#positive_questions \n",
    "len([s for s in wikiqa_f['train'] if s['label']==1]  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e8c4f",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6937745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(filename):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        word_emb = list()\n",
    "        word_dict = dict()\n",
    "        word_emb.append([0])\n",
    "        word_dict['<UNK>'] = 0\n",
    "        for line in f.readlines():\n",
    "            tokens = line.split(' ')\n",
    "            word_emb.append([float(i) for i in tokens[1:]])\n",
    "            word_dict[tokens[0]] = len(word_dict)\n",
    "        word_emb[0] = [0] * len(word_emb[1])\n",
    "    return word_emb, word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c96e377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400001, 400001)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb, word_dict = load_glove(GLOVE_FILE)\n",
    "len(word_emb), len(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e7d426",
   "metadata": {},
   "source": [
    "### DataSet Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "764713b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiQADataset(Dataset):\n",
    "    def __init__(self, word_dict, wikiqa, mode='train'):\n",
    "        self.mode = mode\n",
    "        pad_num = word_dict[PAD_WORD]\n",
    "        \n",
    "        def sent_process(sent, p_len):  # vocab to id -> padding\n",
    "            return [word_dict.get(w.lower(), pad_num) for w in sent[:p_len]] + [pad_num] * (p_len - len(sent)) \n",
    "        \n",
    "        def get_tokens(big_str):\n",
    "            return big_str.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
    "\n",
    "        positive_questions = [s for s in wikiqa if s['label']==1]\n",
    "        quests, answer_pos, answer_neg, answers, labels = [], [], [], [], []\n",
    "        \n",
    "        for sample in tqdm(positive_questions):\n",
    "            quest = sample['question']\n",
    "            quest = sent_process(get_tokens(quest), Q_LENGTH)      # List of vocab indices\n",
    "            pos_ans = sample['answer'] \n",
    "            pos_ans = sent_process(get_tokens(pos_ans), A_LENGTH)  # List of vocab indices\n",
    "            labels.append(1)\n",
    "\n",
    "            qid = sample['question_id']               \n",
    "            # First preference for above question's negative answers provided in dataset\n",
    "            neg_answers = [s['answer'] for s in wikiqa if s['label']==0 and s['question_id']==qid ] # List of strings\n",
    "            # Next filled randomly\n",
    "            more_neg_ans_required = TRAIN_NEG_COUNT - len(neg_answers)\n",
    "            eligible_samples = [s['answer'] for s in wikiqa if s['question_id']!=qid ] # List of strings\n",
    "            more_neg_ans = random.sample(eligible_samples, more_neg_ans_required)\n",
    "            neg_answers = neg_answers + more_neg_ans # List of strings\n",
    "            neg_answers = [sent_process(get_tokens(a), A_LENGTH) for a in neg_answers]  # List of List of vocab indices\n",
    "\n",
    "            quests.append(quest)           # List of List of vocab indices\n",
    "            answer_pos.append(pos_ans)     # List of List of vocab indices\n",
    "            answer_neg.append(neg_answers) # List of List of List of vocab indices\n",
    "            \n",
    "            labels += [0]*len(neg_answers)    # List of binary 0/1\n",
    "            \n",
    "            all_ans = [pos_ans] + neg_answers   # List of List of vocab indices      \n",
    "            answers += all_ans                  # List of List of vocab indices\n",
    "\n",
    "        self.q = torch.LongTensor(quests)        \n",
    "        \n",
    "        if mode == 'train':\n",
    "            self.a_pos = torch.LongTensor(answer_pos)\n",
    "            self.a_neg = torch.LongTensor(answer_neg)                \n",
    "        else: \n",
    "            self.a = torch.LongTensor(answers)\n",
    "            self.y = torch.LongTensor(labels)            \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            return self.q[idx], self.a_pos[idx], self.a_neg[idx]\n",
    "        return self.q[idx], self.a[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self): return self.q.shape[0]\n",
    "\n",
    "    def __str__(self): return f'Dataset {self.mode}: {len(self.q)} samples.'                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe998fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1040/1040 [22:48<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset train: 1040 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 140/140 [00:23<00:00,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset valid: 140 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = WikiQADataset(word_dict, wikiqa_f['train'], mode='train')\n",
    "print(train_data)\n",
    "valid_data = WikiQADataset(word_dict, wikiqa_f['validation'], mode='valid')\n",
    "print(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "748da65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dlr = DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)\n",
    "valid_dlr = DataLoader(valid_data, batch_size=BATCH_SIZE, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c67b8",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0135a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    predict = defaultdict(list)\n",
    "\n",
    "    for q, a, y in dataloader:\n",
    "        cos = model(q, a)\n",
    "        i=0\n",
    "        for pred, label in zip(cos.detach().cpu().numpy(), y.numpy()):\n",
    "            predict[i].append((pred, label))\n",
    "            i += 1\n",
    "\n",
    "    accuracy = 0\n",
    "    MRR = 0\n",
    "    average_precisions = [] \n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")    \n",
    "    for p in predict.values():\n",
    "        \n",
    "        y_true = np.array([s[1] for s in p ])\n",
    "        y_pred = np.array([s[0] for s in p ])\n",
    "        ap = average_precision_score(y_true, y_pred)\n",
    "        average_precisions.append(ap)\n",
    "        \n",
    "        p.sort(key=lambda x: -x[0])\n",
    "        if p[0][1] == 1:\n",
    "            accuracy += 1\n",
    "            \n",
    "        for i, t in enumerate(p):\n",
    "            if t[1] == 1:\n",
    "                MRR += 1 / (i + 1)\n",
    "                break\n",
    "    \n",
    "    accuracy = accuracy / len(predict)\n",
    "    MRR = MRR / len(predict)\n",
    "    mAP = sum(average_precisions)/len(average_precisions)\n",
    "    #warnings.filterwarnings(\"default\")\n",
    "    return accuracy, MRR, mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "478d1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bar(percent, start_str='', end_str='', auto_rm=True):\n",
    "    bar = '=' * int(percent * 50)\n",
    "    bar = '\\r{}|{}| {:.1%} | {}'.format(start_str, bar.ljust(50), percent, end_str)\n",
    "    print(bar, end='', flush=True)\n",
    "    if percent == 1:\n",
    "        print(end=('\\r' + ' ' * len(bar) + '\\r') if auto_rm else '\\n', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9717bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnRate:\n",
    "    def __init__(self, optimizer):\n",
    "        self.opt = optimizer\n",
    "        self.init_lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "        self.epoch = 1\n",
    "\n",
    "    def step(self):\n",
    "        self.epoch += 1\n",
    "        for p in self.opt.param_groups:\n",
    "            p['lr'] = self.init_lr / self.epoch\n",
    "\n",
    "    def get_last_lr(self): return [self.init_lr / self.epoch]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb03b089",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb433e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without Attention\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, word_dim, kernel_count, kernel_size):\n",
    "        super().__init__()\n",
    "        self.encode = nn.Conv1d(\n",
    "            in_channels=word_dim,\n",
    "            out_channels=kernel_count,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=(kernel_size - 1) // 2)\n",
    "\n",
    "    def forward(self, vec):\n",
    "        latent = self.encode(vec.permute(0, 2, 1))\n",
    "        return latent\n",
    "\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, word_dim, hidden_size):\n",
    "        super().__init__()\n",
    "        self.encode = nn.LSTM(input_size=word_dim, hidden_size=hidden_size, bidirectional=True, batch_first=True)\n",
    "\n",
    "    def forward(self, vec):\n",
    "        self.encode.flatten_parameters()\n",
    "        latent, _ = self.encode(vec)\n",
    "        return latent.transpose(-1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "582b7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, init_U='randn'):\n",
    "        super().__init__()\n",
    "        if init_U == 'zeros':\n",
    "            self.U = nn.Parameter(torch.zeros(hidden_size, hidden_size))\n",
    "        else:\n",
    "            self.U = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "\n",
    "    def forward(self, Q, A):\n",
    "        G = Q.transpose(-1, -2) @ self.U.expand(Q.shape[0], -1, -1) @ A\n",
    "        G = torch.tanh(G)\n",
    "        Q_pooling = G.max(dim=-1)[0]\n",
    "        A_pooling = G.max(dim=-2)[0]\n",
    "        Q_pooling = Q_pooling.softmax(dim=-1)\n",
    "        A_pooling = A_pooling.softmax(dim=-1)\n",
    "        rq = Q @ Q_pooling.unsqueeze(-1)\n",
    "        ra = A @ A_pooling.unsqueeze(-1)\n",
    "        rq = rq.squeeze(-1)\n",
    "        ra = ra.squeeze(-1)\n",
    "        return rq, ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61c33403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAModel(nn.Module):\n",
    "    def __init__(self, word_emb, model_name):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.Tensor(word_emb))\n",
    "        self.embedding.weight.requires_grad_()\n",
    "\n",
    "        if 'CNN' in model_name:\n",
    "            self.encode = CNN(self.embedding.embedding_dim, KERNEL_COUNT, KERNEL_SIZE)\n",
    "            if 'AP' in model_name:\n",
    "                self.coAttention = CoAttention(KERNEL_COUNT, init_U='zeros')\n",
    "        elif 'biLSTM' in model_name:\n",
    "            self.encode = BiLSTM(self.embedding.embedding_dim, RNN_HIDDEN)\n",
    "            if 'AP' in model_name:\n",
    "                self.coAttention = CoAttention(RNN_HIDDEN * 2)\n",
    "\n",
    "    def forward(self, questions, answers):\n",
    "        device = next(self.parameters()).device\n",
    "        questions = questions.to(device)\n",
    "        answers = answers.to(device)\n",
    "\n",
    "        q_emb = self.embedding(questions)\n",
    "        a_emb = self.embedding(answers)\n",
    "        Q = self.encode(q_emb)\n",
    "        A = self.encode(a_emb)\n",
    "        if 'AP' in self.model_name:\n",
    "            rq, ra = self.coAttention(Q, A)\n",
    "        else:\n",
    "            rq = Q.max(dim=-1)[0]\n",
    "            ra = A.max(dim=-1)[0]\n",
    "            rq = torch.tanh(rq)\n",
    "            ra = torch.tanh(ra)\n",
    "        cos = torch.sum(rq * ra, dim=-1) / (rq.norm(dim=-1) * ra.norm(dim=-1))\n",
    "        return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55d7f184",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_model(model_name, learning_rate):\n",
    "    model = QAModel(word_emb, model_name).to(device)\n",
    "    model_path = model_name + '.pt'\n",
    "\n",
    "    opt = torch.optim.SGD(model.parameters(), learning_rate, weight_decay=1e-6)\n",
    "    lr_sch = LearnRate(opt)\n",
    "\n",
    "    max_mAP = 0\n",
    "    for epoch in (range(TRAIN_EPOCHS)):\n",
    "        model.train()\n",
    "        total_loss, total_samples = 0, 0\n",
    "        for q, a_pos, a_neg in train_dlr:\n",
    "            cos_pos = model(q, a_pos)\n",
    "            # Only the negative answer with max score value is used to update model weights\n",
    "            input_q = q.unsqueeze(-2).expand(-1, a_neg.shape[-2], -1).reshape(-1, q.shape[-1])\n",
    "            input_a = a_neg.view(-1, a_neg.shape[-1])\n",
    "            cos_neg = model(input_q, input_a)\n",
    "            cos_neg = cos_neg.view(len(q), -1).max(dim=-1)[0]\n",
    "\n",
    "            loss = torch.max(torch.zeros(1).to(cos_pos.device), LOSS_MARGIN - cos_pos + cos_neg).mean()\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += loss.item() * len(q)\n",
    "            total_samples += len(q)\n",
    "            process_bar(total_samples / len(train_dlr.dataset), start_str=f'Epoch {epoch+1}')\n",
    "        curr_lr = lr_sch.get_last_lr()[0]\n",
    "        lr_sch.step()\n",
    "        model.eval()\n",
    "\n",
    "        train_loss = total_loss / total_samples\n",
    "        mAP, MRR, _ = evaluate(model, valid_dlr)\n",
    "        \n",
    "        # Early Stopping \n",
    "        if max_mAP < mAP:\n",
    "            max_mAP = mAP\n",
    "            best_MRR = MRR\n",
    "            if isinstance(model, torch.nn.DataParallel):\n",
    "                torch.save(model.module, model_path)\n",
    "            else:\n",
    "                torch.save(model, model_path)\n",
    "        print(f'Epoch {epoch+1:2d}; learning rate {curr_lr:.4f}; train loss {train_loss:.6f}; '\n",
    "                    f'validation mAP {mAP * 100:.2f}%, MRR {MRR:.4f}')\n",
    "    print(f'End of training') \n",
    "    return max_mAP, best_MRR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc055442",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7baf0ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1; learning rate 0.0500; train loss 0.509099; validation mAP 10.42%, MRR 0.1250\n",
      "Epoch  2; learning rate 0.0250; train loss 0.496364; validation mAP 19.64%, MRR 0.2278\n",
      "Epoch  3; learning rate 0.0167; train loss 0.485139; validation mAP 28.32%, MRR 0.3145\n",
      "Epoch  4; learning rate 0.0125; train loss 0.484369; validation mAP 37.48%, MRR 0.3952\n",
      "Epoch  5; learning rate 0.0100; train loss 0.473812; validation mAP 45.89%, MRR 0.4555\n",
      "Epoch  6; learning rate 0.0083; train loss 0.443380; validation mAP 48.74%, MRR 0.4923\n",
      "Epoch  7; learning rate 0.0071; train loss 0.413030; validation mAP 51.54%, MRR 0.5301\n",
      "Epoch  8; learning rate 0.0063; train loss 0.372736; validation mAP 54.98%, MRR 0.5666\n",
      "Epoch  9; learning rate 0.0056; train loss 0.332482; validation mAP 56.49%, MRR 0.5824\n",
      "Epoch 10; learning rate 0.0050; train loss 0.312259; validation mAP 59.62%, MRR 0.6009\n",
      "Epoch 11; learning rate 0.0045; train loss 0.292061; validation mAP 61.86%, MRR 0.6201\n",
      "Epoch 12; learning rate 0.0042; train loss 0.271882; validation mAP 62.45%, MRR 0.6314\n",
      "Epoch 13; learning rate 0.0038; train loss 0.251720; validation mAP 63.38%, MRR 0.6444\n",
      "Epoch 14; learning rate 0.0036; train loss 0.241571; validation mAP 63.67%, MRR 0.6515\n",
      "Epoch 15; learning rate 0.0033; train loss 0.221434; validation mAP 64.20%, MRR 0.6524\n",
      "Epoch 16; learning rate 0.0031; train loss 0.201307; validation mAP 64.14%, MRR 0.6533\n",
      "Epoch 17; learning rate 0.0029; train loss 0.191188; validation mAP 64.03%, MRR 0.6521\n",
      "Epoch 18; learning rate 0.0028; train loss 0.171078; validation mAP 63.90%, MRR 0.6518\n",
      "Epoch 19; learning rate 0.0026; train loss 0.160973; validation mAP 63.78%, MRR 0.6514\n",
      "Epoch 20; learning rate 0.0025; train loss 0.160875; validation mAP 62.95%, MRR 0.6498\n",
      "End of training\n"
     ]
    }
   ],
   "source": [
    "QA_CNN_mAP, QA_CNN_MRR = run_model('QA-CNN', learning_rate=0.05) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c52d9257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1; learning rate 1.1000; train loss 0.503856; validation mAP 08.51%, MRR 0.1023\n",
      "Epoch  2; learning rate 0.5500; train loss 0.499277; validation mAP 17.86%, MRR 0.1987\n",
      "Epoch  3; learning rate 0.3667; train loss 0.496948; validation mAP 26.22%, MRR 0.2815\n",
      "Epoch  4; learning rate 0.2750; train loss 0.491942; validation mAP 35.45%, MRR 0.3663\n",
      "Epoch  5; learning rate 0.2200; train loss 0.472646; validation mAP 42.72%, MRR 0.4221\n",
      "Epoch  6; learning rate 0.1833; train loss 0.442426; validation mAP 47.86%, MRR 0.4617\n",
      "Epoch  7; learning rate 0.1571; train loss 0.404502; validation mAP 50.42%, MRR 0.5971\n",
      "Epoch  8; learning rate 0.1375; train loss 0.370023; validation mAP 53.91%, MRR 0.6138\n",
      "Epoch  9; learning rate 0.1222; train loss 0.337608; validation mAP 56.22%, MRR 0.6241\n",
      "Epoch 10; learning rate 0.1100; train loss 0.310621; validation mAP 59.31%, MRR 0.6318\n",
      "Epoch 11; learning rate 0.1000; train loss 0.279053; validation mAP 61.42%, MRR 0.6402\n",
      "Epoch 12; learning rate 0.0917; train loss 0.261856; validation mAP 62.65%, MRR 0.6499\n",
      "Epoch 13; learning rate 0.0846; train loss 0.242083; validation mAP 63.31%, MRR 0.6564\n",
      "Epoch 14; learning rate 0.0786; train loss 0.219572; validation mAP 64.81%, MRR 0.6586\n",
      "Epoch 15; learning rate 0.0733; train loss 0.205384; validation mAP 65.33%, MRR 0.6661\n",
      "Epoch 16; learning rate 0.0688; train loss 0.190856; validation mAP 65.68%, MRR 0.6697\n",
      "Epoch 17; learning rate 0.0647; train loss 0.173965; validation mAP 65.93%, MRR 0.6671\n",
      "Epoch 18; learning rate 0.0611; train loss 0.162730; validation mAP 65.85%, MRR 0.6623\n",
      "Epoch 19; learning rate 0.0579; train loss 0.155098; validation mAP 65.68%, MRR 0.6592\n",
      "Epoch 20; learning rate 0.0550; train loss 0.141104; validation mAP 65.01%, MRR 0.6508\n",
      "End of training\n"
     ]
    }
   ],
   "source": [
    "AP_CNN_mAP, AP_CNN_MRR = run_model('AP-CNN', learning_rate=1.1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7da1a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1; learning rate 1.1000; train loss 0.508980; validation mAP 09.33%, MRR 0.1099\n",
      "Epoch  2; learning rate 0.5500; train loss 0.499248; validation mAP 18.25%, MRR 0.1814\n",
      "Epoch  3; learning rate 0.3667; train loss 0.495358; validation mAP 25.28%, MRR 0.2683\n",
      "Epoch  4; learning rate 0.2750; train loss 0.492272; validation mAP 33.61%, MRR 0.3471\n",
      "Epoch  5; learning rate 0.2200; train loss 0.473643; validation mAP 38.78%, MRR 0.4121\n",
      "Epoch  6; learning rate 0.1833; train loss 0.441291; validation mAP 42.86%, MRR 0.4518\n",
      "Epoch  7; learning rate 0.1571; train loss 0.403296; validation mAP 47.33%, MRR 0.4935\n",
      "Epoch  8; learning rate 0.1375; train loss 0.373356; validation mAP 51.45%, MRR 0.5222\n",
      "Epoch  9; learning rate 0.1222; train loss 0.335239; validation mAP 54.62%, MRR 0.5554\n",
      "Epoch 10; learning rate 0.1100; train loss 0.316254; validation mAP 57.39%, MRR 0.5894\n",
      "Epoch 11; learning rate 0.1000; train loss 0.278164; validation mAP 59.22%, MRR 0.6083\n",
      "Epoch 12; learning rate 0.0917; train loss 0.263645; validation mAP 60.94%, MRR 0.6220\n",
      "Epoch 13; learning rate 0.0846; train loss 0.245674; validation mAP 61.39%, MRR 0.6309\n",
      "Epoch 14; learning rate 0.0786; train loss 0.225417; validation mAP 61.75%, MRR 0.6355\n",
      "Epoch 15; learning rate 0.0733; train loss 0.214972; validation mAP 62.15%, MRR 0.6403\n",
      "Epoch 16; learning rate 0.0688; train loss 0.205487; validation mAP 62.87%, MRR 0.6421\n",
      "Epoch 17; learning rate 0.0647; train loss 0.188439; validation mAP 62.79%, MRR 0.6404\n",
      "Epoch 18; learning rate 0.0611; train loss 0.178423; validation mAP 62.51%, MRR 0.6339\n",
      "Epoch 19; learning rate 0.0579; train loss 0.164681; validation mAP 61.99%, MRR 0.6301\n",
      "Epoch 20; learning rate 0.0550; train loss 0.152364; validation mAP 61.72%, MRR 0.6275\n",
      "End of training\n"
     ]
    }
   ],
   "source": [
    "QA_biLSTM_mAP, QA_biLSTM_MRR = run_model('QA-biLSTM', learning_rate=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa545a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1; learning rate 1.1000; train loss 0.516541; validation mAP 10.07%, MRR 0.1121\n",
      "Epoch  2; learning rate 0.5500; train loss 0.498452; validation mAP 18.13%, MRR 0.1955\n",
      "Epoch  3; learning rate 0.3667; train loss 0.496472; validation mAP 26.29%, MRR 0.2598\n",
      "Epoch  4; learning rate 0.2750; train loss 0.489521; validation mAP 34.81%, MRR 0.3342\n",
      "Epoch  5; learning rate 0.2200; train loss 0.474712; validation mAP 41.94%, MRR 0.4045\n",
      "Epoch  6; learning rate 0.1833; train loss 0.446541; validation mAP 47.45%, MRR 0.4664\n",
      "Epoch  7; learning rate 0.1571; train loss 0.419647; validation mAP 51.34%, MRR 0.5182\n",
      "Epoch  8; learning rate 0.1375; train loss 0.375412; validation mAP 54.62%, MRR 0.5452\n",
      "Epoch  9; learning rate 0.1222; train loss 0.332471; validation mAP 56.18%, MRR 0.5641\n",
      "Epoch 10; learning rate 0.1100; train loss 0.314581; validation mAP 58.25%, MRR 0.5922\n",
      "Epoch 11; learning rate 0.1000; train loss 0.273548; validation mAP 60.21%, MRR 0.6144\n",
      "Epoch 12; learning rate 0.0917; train loss 0.267541; validation mAP 61.17%, MRR 0.6295\n",
      "Epoch 13; learning rate 0.0846; train loss 0.245971; validation mAP 62.29%, MRR 0.6379\n",
      "Epoch 14; learning rate 0.0786; train loss 0.223471; validation mAP 63.08%, MRR 0.6450\n",
      "Epoch 15; learning rate 0.0733; train loss 0.218536; validation mAP 63.85%, MRR 0.6505\n",
      "Epoch 16; learning rate 0.0688; train loss 0.204723; validation mAP 64.41%, MRR 0.6589\n",
      "Epoch 17; learning rate 0.0647; train loss 0.189643; validation mAP 64.82%, MRR 0.6571\n",
      "Epoch 18; learning rate 0.0611; train loss 0.172584; validation mAP 64.66%, MRR 0.6508\n",
      "Epoch 19; learning rate 0.0579; train loss 0.166341; validation mAP 64.39%, MRR 0.6482\n",
      "Epoch 20; learning rate 0.0550; train loss 0.154762; validation mAP 63.89%, MRR 0.6461\n",
      "End of training\n"
     ]
    }
   ],
   "source": [
    "AP_biLSTM_mAP, AP_biLSTM_MRR = run_model('AP-biLSTM', learning_rate=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe7ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168624aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fe41c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14efa08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77134d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d6e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b2b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_score(np.array([0, 0, 0, 0, 0]), np.array([0.1, 0.1, 0.1, 0.1, 0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185cbdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.named_parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
