{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eea0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /scratch/sagarsj42/torch-cache\n",
    "!mkdir -p /scratch/sagarsj42/transformers\n",
    "!mkdir -p /scratch/sagarsj42/hf-datasets\n",
    "\n",
    "import os\n",
    "os.chdir('/scratch/sagarsj42')\n",
    "os.environ['TORCH_HOME'] = '/scratch/sagarsj42/torch-cache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/sagarsj42/transformers'\n",
    "os.environ['HF_DATASETS_CACHE'] = '/scratch/sagarsj42/hf-datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc4889f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 23:29:58.027630: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-09 23:29:58.027669: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f28751e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c7c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from explore_wikiqa.ipynb\n",
    "def get_valid_questions(wikiqa):\n",
    "    question_status = dict()\n",
    "\n",
    "    for split in wikiqa:\n",
    "        split_dataset = wikiqa[split]\n",
    "        n_samples = len(split_dataset)\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            qid = split_dataset[i]['question_id']\n",
    "            label = split_dataset[i]['label']\n",
    "            if qid not in question_status:\n",
    "                question_status[qid] = label\n",
    "            else:\n",
    "                question_status[qid] = max(question_status[qid], label)\n",
    "\n",
    "    valid_questions = set([qid for qid in question_status if question_status[qid] > 0])\n",
    "    \n",
    "    return valid_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c1b045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiqaDataset(Dataset):\n",
    "    def __init__(self, wikiqa, tokenizer, max_length):\n",
    "        super(WikiqaDataset, self).__init__()\n",
    "        self.wikiqa = wikiqa\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.wikiqa)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.wikiqa[idx]\n",
    "        question = sample['question'].translate(\n",
    "            str.maketrans('', '', string.punctuation)).lower().strip()\n",
    "        sentence = sample['answer'].translate(\n",
    "            str.maketrans('', '', string.punctuation)).lower().strip()\n",
    "        label = sample['label'] * 1.0\n",
    "        \n",
    "        input_enc = tokenizer(text=question, text_pair=sentence, \n",
    "                              add_special_tokens=True, truncation=True, padding='max_length', \n",
    "                              max_length=self.max_length, \n",
    "                              return_tensors='pt', return_attention_mask=True)\n",
    "        \n",
    "        return (input_enc['input_ids'].flatten(), input_enc['attention_mask'].flatten(), \n",
    "                input_enc['token_type_ids'].flatten(), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff0e8e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertQA(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(BertQA, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(768, 512),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Dropout(p=0.15),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        a = x[1]\n",
    "        x = self.encoder(input_ids=x[0], attention_mask=x[1], token_type_ids=x[2]).last_hidden_state\n",
    "        x = (x * a.unsqueeze(-1) / a.sum(1).view(-1, 1, 1)).sum(1)\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b884f20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home2/sagarsj42/.cache/huggingface/modules/datasets_modules/datasets/wiki_qa/d2d236b5cbdc6fbdab45d168b4d678a002e06ddea3525733a24558150585951c (last modified on Sat Nov 20 13:05:25 2021) since it couldn't be found locally at /scratch/sagarsj42/wiki_qa/wiki_qa.py, or remotely (ConnectionError).\n",
      "Using custom data configuration default\n",
      "Reusing dataset wiki_qa (/scratch/sagarsj42/hf-datasets/wiki_qa/default/0.1.0/d2d236b5cbdc6fbdab45d168b4d678a002e06ddea3525733a24558150585951c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f6a8d66d8d404887ff26fc7bd335bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec426a48ef94326ad1a3fd0ecc9d846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b33ae38cae94559814d30f9200faba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['question_id', 'question', 'document_title', 'answer', 'label'],\n",
       "        num_rows: 2351\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question_id', 'question', 'document_title', 'answer', 'label'],\n",
       "        num_rows: 1130\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['question_id', 'question', 'document_title', 'answer', 'label'],\n",
       "        num_rows: 8672\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikiqa = datasets.load_dataset('wiki_qa')\n",
    "valid_questions = get_valid_questions(wikiqa)\n",
    "wikiqa_f = wikiqa.filter(lambda sample: sample['question_id'] in valid_questions)\n",
    "\n",
    "wikiqa_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a9d670c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "encoder = BertModel.from_pretrained('bert-base-uncased')\n",
    "encoder.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd75f271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertQA(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "    (1): Dropout(p=0.25, inplace=False)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (4): Dropout(p=0.15, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertQA(encoder)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c806783d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8672"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_lengths = list()\n",
    "\n",
    "for sample in wikiqa_f['train']:\n",
    "    question = sample['question']\n",
    "    sentence = sample['answer']\n",
    "    tok_len = len(tokenizer(text=question, text_pair=sentence)['input_ids'])\n",
    "    tok_lengths.append(tok_len)\n",
    "    \n",
    "len(tok_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35e14889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(tok_lengths, density=False, bins=50)\n",
    "plt.xlabel('tokenized length')\n",
    "plt.ylabel('counts')\n",
    "plt.title('Histogram of tokenized question-sentence lengths')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab190090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 20\n",
    "learning_rate = 5e-5\n",
    "n_epochs = 4\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-7)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3c0b926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8672, 1130, 2351)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = WikiqaDataset(wikiqa_f['train'], tokenizer, max_length=64)\n",
    "dev_dataset = WikiqaDataset(wikiqa_f['validation'], tokenizer, max_length=64)\n",
    "test_dataset = WikiqaDataset(wikiqa_f['test'], tokenizer, max_length=64)\n",
    "\n",
    "len(train_dataset), len(dev_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a362cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271, 36, 74)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "len(train_dataloader), len(dev_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "436313b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, optimizer, criterion, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    n_batches = len(dataloader)\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for sample in dataloader:\n",
    "        sample = [s.to(device) for s in sample]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(sample[:-1])\n",
    "        loss = criterion(output.flatten(), sample[-1].flatten())\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf683d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "train_epoch(train_dataloader, model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aff9180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
